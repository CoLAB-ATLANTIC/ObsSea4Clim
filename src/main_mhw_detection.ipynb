{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports_and_functions.py\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_ratio = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = InputParameters(\n",
    "    window_size = timedelta(days=728), #approx 2 years\n",
    "    step_size = timedelta(days=546), #approx 18 months (three quarters of the window_size)\n",
    "    first_year=1982, last_year=2022,\n",
    "    min_intensity=0.2, min_days=5,\n",
    "    min_pixels = int(250_000/(downsample_ratio**2)),\n",
    "    min_frame = int(10_000/(downsample_ratio**2)),\n",
    "    output_folder = '/media/eoserver/AnaO_ATL/JP_ATL/mhw_labeled_dataset/2d_detection/',\n",
    "    reset=True,\n",
    "    neighbours= [[1,1,1],\n",
    "                 [1,1,1],\n",
    "                 [1,1,1]],\n",
    "    prov_list = ['NADR', 'NASE', 'NASW', 'NATR',\n",
    "             'CARB', 'NECS', 'SARC', 'ARCT',\n",
    "             'GFST', 'NWCS', 'BPLR', 'CNRY'],\n",
    "    MASK_PROVINCES=False,\n",
    "    longhurst_path = '/home/eoserver/beatriz/JP/PROVINCES/NA_longhurst.shp'\n",
    "    )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=params.getp('output_folder')\n",
    "[f for f in os.listdir(directory) if f.endswith('.nc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f'/media/eoserver/AnaO_ATL/JP_ATL/mhw_data/mhw_{year}.nc' for year in range(params.getp('first_year'), params.getp('last_year')+1)]\n",
    "data = xr.open_mfdataset(files)#, chunks={'time': 200}\n",
    "\n",
    "#Not included in the longhurst file:\n",
    "# [CAMR, GUIA, WTRA, ETRA, GUIN, MEDI]\n",
    "\n",
    "if params.getp('MASK_PROVINCES'):\n",
    "    merged_gdf = get_gdf_merged_provinces(params)\n",
    "else: merged_gdf=None\n",
    "\n",
    "data = preprocess_nc(data, params.getp('min_intensity'), merged_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.to_datetime(data['time'].values).to_pydatetime()\n",
    "first_day = time[0]\n",
    "last_day = time[-1]\n",
    "del time\n",
    "\n",
    "window_start_day = first_day\n",
    "window_end_day = first_day + params.getp('window_size')\n",
    "\n",
    "step_size = params.getp('step_size')\n",
    "last_lbl=1\n",
    "\n",
    "mapping_dir = '/home/eoserver/beatriz/JP/data/label_mapping_total.pkl'\n",
    "\n",
    "#choose the detection method\n",
    "detect_mhws = [detect_mhws_2d, detect_mhws_cc3d][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample nc file just for developing\n",
    "data = downsample_netcdf(data, ratio=downsample_ratio)\n",
    "print(f'(lat, lon) size: ({len(data.lat.values)}, {len(data.lon.values)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #if you want to start mid process (already have some years processed and you want to pick up the process)\n",
    "# params.setp('reset', False)\n",
    "# folder_path = params.getp('output_folder')\n",
    "# previous_overlap = xr.open_dataset(folder_path + 'previous_overlap.nc')\n",
    "\n",
    "# previous_overlap_time = pd.to_datetime(previous_overlap['time'].values).to_pydatetime()\n",
    "# overlap_start = previous_overlap_time[0]\n",
    "# overlap_end = previous_overlap_time[-1]\n",
    "# window_start_day = overlap_start\n",
    "# window_end_day = window_start_day + params.getp('window_size')\n",
    "\n",
    "# last_lbl = previous_overlap['mhw_label'].max().item() +1\n",
    "\n",
    "\"\"\" # if you want to start mid process (already have some years processed and you want to pick up the process)\n",
    "folder_path = params.getp('output_folder')\n",
    "ds = open_most_recent_nc_file(folder_path)\n",
    "\n",
    "params.setp('reset', False)\n",
    "window_start_day, window_end_day, previous_overlap, overlap_start, overlap_end = begin_midway(ds, params.getp('window_size'), step_size)\n",
    "\n",
    "last_lbl = ds['mhw_label'].max().item() +1\n",
    "ds.close() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_memory=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports_and_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.getp('reset'):\n",
    "    if os.path.exists(mapping_dir): os.remove(mapping_dir)\n",
    "    outpath = params.getp('output_folder') + 'mhw_dataset.nc'\n",
    "    if os.path.exists(outpath): remove_all_files_in_folder(params.getp('output_folder'))\n",
    "\n",
    "while window_start_day < last_day:\n",
    "    current_time = datetime.now().strftime('%H:%M')\n",
    "    print(f'window: {window_start_day} to {window_end_day}; last label: {last_lbl} [{current_time}]') \n",
    "    if debug_memory: memory_print('cycle beginning')\n",
    "\n",
    "    #detect mhws in current window\n",
    "    current_window_nc = data.sel(time = slice(window_start_day, window_end_day))\n",
    "    current_window = current_window_nc.intensity.values\n",
    "    \n",
    "    if debug_memory: memory_print('before detect_mhws')\n",
    "    current_window, last_lbl = detect_mhws(current_window, last_lbl , params)\n",
    "    current_window_nc['mhw_label'] = (('time', 'lat', 'lon'), current_window)\n",
    "    current_window_nc = current_window_nc.drop_vars('intensity')\n",
    "    del current_window\n",
    "    if debug_memory: memory_print('after detect_mhws')\n",
    "    \n",
    "    if window_start_day != first_day:   \n",
    "        #get overlap windows\n",
    "        current_overlap = current_window_nc.sel(time = slice(overlap_start, overlap_end))\n",
    "        current_overlap = current_overlap['mhw_label'].values\n",
    "        previous_overlap = previous_overlap['mhw_label'].values\n",
    "        \n",
    "        if debug_memory: memory_print('before update_overlap')\n",
    "        overlap_window, label_mapping = update_overlap(previous_overlap, current_overlap)\n",
    "        del previous_overlap\n",
    "        if debug_memory: memory_print('after update_overlap')\n",
    "        \n",
    "        current_window = current_window_nc.sel(time = slice(overlap_end + timedelta(days=1), window_end_day))\n",
    "        current_window = current_window['mhw_label'].values\n",
    "        current_window = relabel_data_window(current_window, label_mapping)\n",
    "        if debug_memory: memory_print('after relabel_data_window')\n",
    "        \n",
    "        current_window = np.concatenate((overlap_window, current_window))\n",
    "        current_window_nc['mhw_label'] =  (('time', 'lat', 'lon'), current_window)\n",
    "        del current_window\n",
    "        if debug_memory: memory_print('after concat window')\n",
    "    \n",
    "    window_start_day_prev = window_start_day\n",
    "    window_end_day_prev = window_end_day\n",
    "    \n",
    "    if window_end_day >= last_day:\n",
    "        lst_time = current_window_nc.time.values\n",
    "        print(f'LAST window: {to_datetime(lst_time[0])} to {to_datetime(lst_time[-1])}; last label: {last_lbl}')\n",
    "        str1=to_datetime(lst_time[0]).strftime('%Y-%m-%d')\n",
    "        str2=to_datetime(lst_time[-1]).strftime('%Y-%m-%d'); del lst_time\n",
    "        name = f'{str1}_to_{str2}'\n",
    "        save_window(current_window_nc, params.getp('output_folder'), name + '.nc',  separate=True) #exception for the last timestep\n",
    "        del current_window_nc\n",
    "        break\n",
    "    else:\n",
    "        if debug_memory: memory_print('before saving window')\n",
    "        window_start_day += step_size\n",
    "        window_end_day += step_size\n",
    "        \n",
    "        previous_window_save = current_window_nc.sel(time = slice(window_start_day_prev,\n",
    "                                                               window_start_day-timedelta(days=1)))\n",
    "        \n",
    "        str1=window_start_day_prev.strftime('%Y-%m-%d')\n",
    "        str2=window_start_day-timedelta(days=1); str2=str2.strftime('%Y-%m-%d')\n",
    "        name = f'{str1}_to_{str2}'\n",
    "        \n",
    "        video_folder = '/home/eoserver/beatriz/JP/mhw_detection_jun_version/videos/no_prov/'\n",
    "        save_video(previous_window_save.mhw_label.values, video_folder + name + '.mp4', fps=5)\n",
    "        \n",
    "        save_window(previous_window_save, params.getp('output_folder'), name + '.nc',  separate=True)\n",
    "        del previous_window_save\n",
    "        if debug_memory: memory_print('after saving window')\n",
    "    \n",
    "    # Find the overlapping date range\n",
    "    overlap_start, overlap_end = find_overlap_dates(window_start_day_prev, window_end_day_prev,\n",
    "                                                    window_start_day, window_end_day)\n",
    "    \n",
    "    previous_overlap = current_window_nc.sel(time = slice(overlap_start, overlap_end))\n",
    "    backup_overlap(params.getp('output_folder'),'previous_overlap.nc','previous_overlap_backup.nc')\n",
    "    save_window(previous_overlap, params.getp('output_folder'), 'previous_overlap.nc',  separate=True)\n",
    "    del current_window_nc\n",
    "\n",
    "#add label mapping for labels that didnt appear in the overlap\n",
    "adjust_label_mapping(last_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASS THROUGH FINAL NETCDF AND UPDATE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mapping_dir = '/home/eoserver/beatriz/JP/data/label_mapping_total.pkl'\n",
    "\n",
    "with open(mapping_dir, 'rb') as f:\n",
    "    label_mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dir = '/home/eoserver/beatriz/JP/data/label_mapping_total.pkl'\n",
    "\n",
    "with open(mapping_dir, 'rb') as f:\n",
    "    label_mapping = pickle.load(f)\n",
    "\n",
    "for file in files_with_substring:\n",
    "    chunk = xr.open_dataset(params.getp('output_folder')+file, chunks={'time': 200})\n",
    "\n",
    "    print(file)  \n",
    "    \n",
    "    old_labels = list(np.unique(chunk['mhw_label'].values))\n",
    "    old_labels.remove(0)\n",
    "    \n",
    "    for old_lbl in old_labels:\n",
    "        new_label=label_mapping[old_lbl]\n",
    "        if old_lbl != new_label:\n",
    "            print(f'before: {old_lbl} to {new_label}')\n",
    "            chunk = chunk.where(chunk == old_lbl, new_label)\n",
    "    \n",
    "    os.remove(params.getp('output_folder')+file)\n",
    "    chunk.to_netcdf(params.getp('output_folder')+file, compute=True)\n",
    "    chunk.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports_and_functions\n",
    "%run sep_id_functions\n",
    "\n",
    "downsample_ratio=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = InputParameters(\n",
    "    window_size = timedelta(days=728), #approx 2 years\n",
    "    step_size = timedelta(days=546), #approx 18 months (three quarters of the window_size)\n",
    "    first_year=1982, last_year=2022,\n",
    "    min_intensity=0.2, min_duration=5,\n",
    "    min_pixels = int(250_000/(downsample_ratio**2)),\n",
    "    output_folder = '/media/eoserver/AnaO_ATL/JP_ATL/mhw_labeled_dataset/2d_detection/',\n",
    "    mhw_output_folder =  '/media/eoserver/AnaO_ATL/JP_ATL/mhw_labeled_dataset/2d_detection/detected_mhws/CHECK!!!',\n",
    "    reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_dates_dir = '/home/eoserver/beatriz/JP/data/lbl_dates_no_overlap.pkl'\n",
    "with open(lbl_dates_dir, 'rb') as f:\n",
    "    lbl_dates = pickle.load(f)\n",
    "    \n",
    "labels = lbl_dates.keys()\n",
    "\n",
    "folder_path = params.getp('output_folder')  # replace with your folder path\n",
    "substring = '.'\n",
    "files_with_substring = get_files_with_substring(folder_path, substring)\n",
    "files = [folder_path + file for file in files_with_substring]\n",
    "\n",
    "dataset = xr.open_mfdataset(files, chunks={'time': 200})\n",
    "time_arr = dataset.time.values\n",
    "latitudes = dataset['lat'].values\n",
    "longitudes = dataset['lon'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAO_df = pd.read_csv('/home/eoserver/beatriz/JP/data/NAO_data_update.csv')\n",
    "NAO_df = NAO_df.rename(columns={NAO_df.columns[0]: 'Year'})\n",
    "\n",
    "prov_arrays = get_province_asarray(map_bounds = (len(dataset.lat.values), len(dataset.lon.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_number = 1\n",
    "for lbl in list(labels):\n",
    "    start_date = to_datetime(lbl_dates[lbl][0])\n",
    "    for end_date in lbl_dates[lbl][1:]:\n",
    "        end_date = to_datetime(end_date)\n",
    "        if (end_date-start_date).days >=params.getp('min_duration'):\n",
    "            str1 = start_date.strftime('%Y-%m-%d'); str2 = end_date.strftime('%Y-%m-%d')\n",
    "            \n",
    "            chunk = dataset.sel(time=slice(start_date, end_date))\n",
    "            time_range = chunk.time.values\n",
    "            \n",
    "            frames = chunk['mhw_label'].values; del chunk\n",
    "            frames = np.where(frames!=lbl, 0, 1)\n",
    "            \n",
    "            total_pixels = np.count_nonzero(frames)\n",
    "            if total_pixels >= params.getp('min_pixels'):\n",
    "                print(f'mhw {serial_number} from label {lbl}: from {str1} to {str2}; pixels: {total_pixels}')\n",
    "                \n",
    "                mhw_data = get_mhw_ids(frames, start_date, end_date, prov_arrays, NAO_df, serial_number, total_pixels)\n",
    "                serial_number += 1\n",
    "                \n",
    "                mhw_data['time_array'] = time_range\n",
    "                save_output_nc(mhw_data, params, latitudes, longitudes)\n",
    "                \n",
    "                \"\"\" name = mhw_data['ID']\n",
    "                with open(params.getp('mhw_output_folder') + name + '.pkl', 'wb') as f:\n",
    "                    pickle.dump(mhw_data, f) \"\"\"\n",
    "                    \n",
    "                del mhw_data\n",
    "            \n",
    "            del frames\n",
    "        start_date = end_date + timedelta(days=1)\n",
    "\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(s):\n",
    "    last_part = s.rsplit('/', 1)[-1]\n",
    "    parts = last_part.split('_')\n",
    "    year = int(parts[2])\n",
    "    return year\n",
    "\n",
    "folder_path = params.getp('mhw_output_folder')\n",
    "substring = '.'\n",
    "files_with_substring = get_files_with_substring(folder_path, substring)\n",
    "files = [folder_path + file for file in files_with_substring]\n",
    "files = sorted(files, key=extract_year)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(files):\n",
    "    with open(file, 'rb') as f:\n",
    "        mhw = pickle.load(f)\n",
    "\n",
    "    filename = file.rsplit('/', 1)[-1]\n",
    "    save_video(mhw['Areas'], f'./videos/{i}_{filename[:-4]}.mp4', labeling= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
